{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI, ChatVertexAI\n",
    "from langchain.embeddings import OpenAIEmbeddings, VertexAIEmbeddings\n",
    "from langchain.schema import (\n",
    "    AIMessage, \n",
    "    HumanMessage, \n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF you are running this please just insert the os keys that was given\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/dark/VS-CodePythonProjects/Gamefication-Retirement/KeysAI')\n",
    "\n",
    "import OpenAIKeysTIAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Transaction_File_Creator/financial_game_summary.txt', 'r') as f:\n",
    "    data_to_summarize = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_type='azure'\n",
    "openai.api_base = os.environ[\"OPENAI_API_HOST\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "base_model_name=\"tiaa-gpt-4-32k\"\n",
    "chosen_llm = AzureChatOpenAI(\n",
    "        openai_api_base=os.environ[\"OPENAI_API_HOST\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "        deployment_name=base_model_name,\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        temperature=0\n",
    "    )\n",
    "embedding_model_name = 'tiaa-text-embedding-ada-002'\n",
    "chosen_embedding_model = OpenAIEmbeddings(\n",
    "        deployment=embedding_model_name,\n",
    "        openai_api_base=os.environ[\"OPENAI_API_EMBEDDING_HOST\"],\n",
    "        openai_api_version= os.environ[\"OPENAI_API_VERSION\"],\n",
    "        openai_api_key=os.environ[\"OPENAI_API_EMBEDDING_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        chunk_size=16\n",
    "    )\n",
    "finalAnswerTheQuestionModel = AzureChatOpenAI(\n",
    "        openai_api_base=os.environ[\"OPENAI_API_HOST\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "        deployment_name=base_model_name,\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        temperature=0,\n",
    "        verbose = True\n",
    "    )\n",
    "condensingTheQuestionModel = AzureChatOpenAI(\n",
    "        openai_api_base=os.environ[\"OPENAI_API_HOST\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "        deployment_name=base_model_name,\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        temperature=0, \n",
    "        verbose = True\n",
    "    )\n",
    "memory = ConversationBufferMemory(\n",
    "    output_key='answer',\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorstore(text):\n",
    "    new_doc = Document(page_content=text, metadata=[])\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    chunked_docs = text_splitter.split_documents([new_doc])\n",
    "    vectorstore = FAISS.from_documents(chunked_docs, chosen_embedding_model)\n",
    "    return(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_vector=vectorstore(data_to_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm = finalAnswerTheQuestionModel,\n",
    "    retriever = current_vector.as_retriever(),\n",
    "    condense_question_llm = condensingTheQuestionModel,\n",
    ")\n",
    "source_with_qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm = finalAnswerTheQuestionModel,\n",
    "    retriever = current_vector.as_retriever(\n",
    "                                         search_kwargs={\n",
    "                                            \"k\": 8\n",
    "                                            }),\n",
    "    condense_question_llm = condensingTheQuestionModel,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Account ID: pznbjQnW6KienZgWVB7EiMQJezZLo1hpqangP\n",
      "   - Final Score for the month: 68\n",
      "   - This user lost points for exceeding the essential budget. The score from savings was 10, but there is no information about the score from essentials and non-essentials budget compliance.\n",
      "\n",
      "2. Account ID: MAD9LQDKnrC6ybzMWgE9fl6XoRx8eBtL5qyxw\n",
      "   - Final Score for the month: 68\n",
      "   - This user also lost points for exceeding the essential budget. The score from savings was 10, but there is no information about the score from essentials and non-essentials budget compliance.\n",
      "\n",
      "3. Account ID: 1GErvgE9ANFdK46JejG7iJDVnGjg9qCpaBo7n\n",
      "   - Final Score for the month: 68\n",
      "   - This user had several transactions, both essential and non-essential. They lost points for exceeding the essential budget in multiple months. The base score was 60, with a score of -4 from essentials budget compliance, a score of 2 from non-essentials budget compliance, and a score of 10 from savings. Despite exceeding the essential budget, they complied with the non-essential budget, which helped maintain their score.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = f\"Give A break down for all users and there financial scores, give an in depth overview on why their scores are the way they are.\"\n",
    "result = source_with_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "ans = result['answer']\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can only provide information on two users based on the context provided.\n",
      "\n",
      "1. Account ID: pznbjQnW6KienZgWVB7EiMQJezZLo1hpqangP\n",
      "   - Base Score: 60\n",
      "   - Score from Essentials Budget Compliance: -4 (This user lost points for exceeding the essential budget)\n",
      "   - Score from Non-Essentials Budget Compliance: 2 (This user complied with the non-essential budget)\n",
      "   - Score from Savings: 10\n",
      "   - Final Score for the month: 68\n",
      "\n",
      "2. Account ID: MAD9LQDKnrC6ybzMWgE9fl6XoRx8eBtL5qyxw\n",
      "   - The specific breakdown for this user is not provided in the context, but it is mentioned that they lost points for exceeding the essential budget. Their final score for the month is also 68.\n",
      "\n",
      "Without more specific information, I can't provide a more in-depth overview.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = f\"\"\n",
    "result = source_with_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "ans = result['answer']\n",
    "\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
