{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"Generative AI\" part of the code\n",
    "\n",
    "This is where we take the text output of the code and pipe it into GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Langchain and openai before running this cell\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatVertexAI\n",
    "from langchain.embeddings import OpenAIEmbeddings, VertexAIEmbeddings\n",
    "from langchain.schema import (\n",
    "    AIMessage, \n",
    "    HumanMessage, \n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF you are running this please just insert the os keys that was given\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Gamefication-Retirement/KeysAI')\n",
    "\n",
    "import OpenAIKeysTIAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file\n",
    "with open('../Transaction_File_Creator/financial_game_summary.txt', 'r') as f:\n",
    "    data_to_summarize = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that was given to us from TIAA to run there model\n",
    "\n",
    "openai.api_type='azure'\n",
    "openai.api_base = os.environ[\"OPENAI_API_HOST\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "base_model_name=\"tiaa-gpt-4-32k\"\n",
    "chosen_llm = AzureChatOpenAI(\n",
    "        openai_api_base=os.environ[\"OPENAI_API_HOST\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "        deployment_name=base_model_name,\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        temperature=0\n",
    "    )\n",
    "embedding_model_name = 'tiaa-text-embedding-ada-002'\n",
    "chosen_embedding_model = OpenAIEmbeddings(\n",
    "        deployment=embedding_model_name,\n",
    "        openai_api_base=os.environ[\"OPENAI_API_EMBEDDING_HOST\"],\n",
    "        openai_api_version= os.environ[\"OPENAI_API_VERSION\"],\n",
    "        openai_api_key=os.environ[\"OPENAI_API_EMBEDDING_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        chunk_size=16\n",
    "    )\n",
    "finalAnswerTheQuestionModel = AzureChatOpenAI(\n",
    "        openai_api_base=os.environ[\"OPENAI_API_HOST\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "        deployment_name=base_model_name,\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        max_tokens=4096,\n",
    "        temperature=0,\n",
    "        verbose = True\n",
    "    )\n",
    "condensingTheQuestionModel = AzureChatOpenAI(\n",
    "        openai_api_base=os.environ[\"OPENAI_API_HOST\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "        deployment_name=base_model_name,\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        max_tokens=4096,\n",
    "        temperature=0, \n",
    "        verbose = True\n",
    "    )\n",
    "memory = ConversationBufferMemory(\n",
    "    output_key='answer',\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we store the data in the vectorstore function for more input \n",
    "# also given to us by TIAA\n",
    "\n",
    "def vectorstore(text):\n",
    "    new_doc = Document(page_content=text, metadata=[])\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    chunked_docs = text_splitter.split_documents([new_doc])\n",
    "    vectorstore = FAISS.from_documents(chunked_docs, chosen_embedding_model)\n",
    "    return(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the output text to vector store so we can input this to gpt \n",
    "current_vector = vectorstore(data_to_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm = finalAnswerTheQuestionModel,\n",
    "    retriever = current_vector.as_retriever(),\n",
    "    condense_question_llm = condensingTheQuestionModel,\n",
    ")\n",
    "source_with_qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm = finalAnswerTheQuestionModel,\n",
    "    retriever = current_vector.as_retriever(\n",
    "                                         search_kwargs={\n",
    "                                            \"k\": 8\n",
    "                                            }),\n",
    "    condense_question_llm = condensingTheQuestionModel,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, there are three users with the following financial scores:\n",
      "\n",
      "1. Account ID: pznbjQnW6KienZgWVB7EiMQJezZLo1hpqangP\n",
      "   - Final Score for the month: 68\n",
      "   - This user lost points for exceeding the essential budget. The exact amount by which the budget was exceeded is not provided. However, the user did score 10 points from savings, indicating some level of financial discipline.\n",
      "\n",
      "2. Account ID: MAD9LQDKnrC6ybzMWgE9fl6XoRx8eBtL5qyxw\n",
      "   - Final Score for the month: 68\n",
      "   - This user also lost points for exceeding the essential budget. The exact amount by which the budget was exceeded is not provided. Like the previous user, this user also scored 10 points from savings.\n",
      "\n",
      "3. Account ID: 1GErvgE9ANFdK46JejG7iJDVnGjg9qCpaBo7n\n",
      "   - Final Score for the month: 68\n",
      "   - This user consistently exceeded their essential budget across multiple months, losing 4 points each time for non-compliance. However, they consistently complied with their non-essential budget, gaining 2 points each time. They also scored 10 points from savings. The user's spending on essentials varied from month to month, but it was consistently higher than their budget for essentials.\n",
      "\n",
      "In all cases, the users' scores are affected by their compliance with their essential budget. Despite exceeding their essential budgets, all users managed to maintain a final score of 68 due to their savings and compliance with their non-essential budgets.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = f\"Give A break down for all users and there financial scores, give an in depth overview on why their scores are the way they are.\"\n",
    "result = source_with_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "ans = result['answer']\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a financial review and summary for John, who holds the account with ID pznbjQnW6KienZgWVB7EiMQJezZLo1hpqangP:\n",
      "\n",
      "John started with a base score of 60. He lost 4 points for exceeding the essential budget, but he gained 2 points for complying with the non-essential budget. He also gained an additional 10 points from savings. \n",
      "\n",
      "Therefore, his final score for the month is 68. \n",
      "\n",
      "In summary, John needs to manage his essential budget better to avoid losing points in the future. However, he is doing well with his non-essential budget and savings.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"Generate a financial review and summary for the account with ID pznbjQnW6KienZgWVB7EiMQJezZLo1hpqangP. Provide the account holder, John, with a detailed breakdown of his score.\"\n",
    "result = source_with_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "ans = result['answer']\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Account ID\": \"pznbjQnW6KienZgWVB7EiMQJezZLo1hpqangP\",\n",
      "  \"Transactions\": [\n",
      "    {\n",
      "      \"Transaction\": \"United Airlines\",\n",
      "      \"Amount\": \"$500.00\",\n",
      "      \"Category\": \"Non-Essential\"\n",
      "    },\n",
      "    {\n",
      "      \"Transaction\": \"Tectra Inc\",\n",
      "      \"Amount\": \"$500.00\",\n",
      "      \"Category\": \"Other\"\n",
      "    },\n",
      "    {\n",
      "      \"Transaction\": \"AUTOMATIC PAYMENT - THANK\",\n",
      "      \"Amount\": \"$2078.50\",\n",
      "      \"Category\": \"Essential\"\n",
      "    },\n",
      "    {\n",
      "      \"Transaction\": \"KFC\",\n",
      "      \"Amount\": \"$500.00\",\n",
      "      \"Category\": \"Non-Essential\"\n",
      "    },\n",
      "    {\n",
      "      \"Transaction\": \"Madison Bicycle Shop\",\n",
      "      \"Amount\": \"$500.00\",\n",
      "      \"Category\": \"Other\"\n",
      "    },\n",
      "    {\n",
      "      \"Transaction\": \"Touchstone Climbing\",\n",
      "      \"Amount\": \"$78.50\",\n",
      "      \"Category\": \"Non-Essential\"\n",
      "    }\n",
      "  ],\n",
      "  \"Month-Year\": [\n",
      "    \"2021-11\",\n",
      "    \"2022-03\",\n",
      "    \"2022-05\",\n",
      "    \"2022-02\",\n",
      "    \"2022-06\",\n",
      "    \"2022-07\",\n",
      "    \"2022-01\"\n",
      "  ],\n",
      "  \"Total spending on Essentials\": \"$2078.50\",\n",
      "  \"Total spending on Non-Essentials\": \"$1078.50\",\n",
      "  \"Budget for Essentials\": \"$1973.12\",\n",
      "  \"Budget for Non-Essentials\": \"$1183.88\",\n",
      "  \"Compliance with Essential budget\": \"No\",\n",
      "  \"Base Score\": \"60\",\n",
      "  \"Score from Essentials Budget Compliance\": \"-4\",\n",
      "  \"Score from Non-Essentials Budget Compliance\": \"2\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"respond with a json like response no text response for the user:pznbjQnW6KienZgWVB7EiMQJezZLo1hpqangP with all the elements you find about that user\"\n",
    "result = source_with_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "ansjson = result['answer']\n",
    "\n",
    "print(ansjson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing to JSON for the app dev to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dont run if userdata already exists\n",
    "\n",
    "# json_file_name = 'userdata.json'\n",
    "\n",
    "# with open(json_file_name, 'a', encoding='utf-8') as file:\n",
    "#     file.write(ansjson + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
